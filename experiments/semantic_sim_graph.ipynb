{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a graph based on semantic similarities between tokens\n",
    "# This is done to compare the quality of graphs generated by a language model, vs sentence embeddings\n",
    "# TODO: use similarity cutoffs rather than hardcoded number of connections\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import os\n",
    "\n",
    "MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "MAX_CONNECTIONS = 12\n",
    "IN_PATH = \"path/to/input/vocab.txt\" \n",
    "\n",
    "def load_vocab(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def generate_semantic_graph(vocab, model_name, max_connections):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    \n",
    "    # Calculate embeddings for all words at once\n",
    "    embeddings = model.encode(vocab, show_progress_bar=False)\n",
    "    \n",
    "    # Calculate pairwise similarities using matrix operations\n",
    "    similarity_matrix = cosine_similarity(embeddings)\n",
    "    \n",
    "    semantic_graph = {}\n",
    "    for i, word in enumerate(vocab):\n",
    "        # Get similarities for this word with all other words\n",
    "        similarities = similarity_matrix[i]\n",
    "        \n",
    "        # Sort similarities, excluding self\n",
    "        sorted_indices = np.argsort(similarities)[::-1][1:max_connections+1]\n",
    "        \n",
    "        # Get the most similar words\n",
    "        similar_words = [vocab[j] for j in sorted_indices]\n",
    "        \n",
    "        semantic_graph[word] = similar_words\n",
    "    \n",
    "    return semantic_graph\n",
    "\n",
    "# Load the vocabulary\n",
    "vocab = load_vocab(path=IN_PATH)\n",
    "\n",
    "# Generate a new graph based on semantic similarities\n",
    "semantic_graph = generate_semantic_graph(vocab, MODEL_NAME, MAX_CONNECTIONS)\n",
    "\n",
    "# Generate output file path based on input parameters\n",
    "base_name = os.path.splitext(os.path.basename(IN_PATH))[0]\n",
    "OUT_PATH = f\"{base_name}_semantic_M{MODEL_NAME.replace('-', '_')}_C{MAX_CONNECTIONS}.json\"\n",
    "\n",
    "# Save the semantically generated graph\n",
    "with open(OUT_PATH, 'w') as f:\n",
    "    json.dump(semantic_graph, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-semantic-search-6iwadsk4-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
